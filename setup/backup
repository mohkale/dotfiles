#!/usr/bin/env python3
"""
Script to prepare backup current host for a new installation.

The backups created by this script aren't reproducable. You can't take a backup
directory and restore your system to it's working state. Instead the backups act
as a reference for all the important or meaningful files you have on your system
and may need when moving to a new system.
"""

import functools
import glob
import itertools
import logging
import os
import pathlib
import shutil
import subprocess
import sys

# ┌───────────┐
# │ Constants │
# └───────────┘

XDG_DEV = os.environ.get("XDG_DEV_HOME", os.path.expanduser("~/prog"))
XDG_CONFIG = os.environ.get("XDG_CONFIG_HOME", os.path.expanduser("~/.config"))
XDG_DATA = os.environ.get("XDG_DATA_HOME", os.path.expanduser("~/.local/share"))
XDG_CACHE = os.environ.get("XDG_CACHE_HOME", os.path.expanduser("~/.cache"))
XDG_TEMP = os.environ.get("XDG_TEMP_DIR", os.path.expanduser("~/.local/temp"))
XDG_DOCS = os.environ.get("XDG_DOCUMENTS_DIR", os.path.expanduser("~/Documents"))

# Specify the individual paths you'd like to be backed up
# as a chain of [[https://docs.python.org/3/library/glob.html][globs]].
#
# If any of the globs don't expand to a valid path, they
# won't be backed up (simple as).
PATHS = (
    f"{XDG_DEV}/.modules/python",
    f"{XDG_DEV}/conf",
    f"{XDG_DEV}/logs",
    # TODO: Media directories
    "~/media",
    f"{XDG_DOCS}",
    # TODO: crontab
    f"{XDG_CONFIG}/aliases/*.private",
    f"{XDG_CONFIG}/shenv.local",
    f"{XDG_CONFIG}/pylog",
    # Browser bookmarks
    f"{XDG_CONFIG}/google-chrome",
    f"{XDG_CONFIG}/BraveSoftware/Brave-Browser/Default/Bookmarks",
    "~/.mozilla/firefox/*/places.sqlite",
    "~/.tor-browser/app/Browser/TorBrowser/Data/Browser/*/places.sqlite",
    # Tmux
    f"{XDG_CONFIG}/tmux/disk-free.conf",
    f"{XDG_CONFIG}/tmux/tmux-local.conf",
    f"{XDG_CONFIG}/tmuxinator",
    f"{XDG_CONFIG}/tmuxp",
    # Transmission torrent database
    f"{XDG_CONFIG}/transmission*",
    # Vim shared data (undo history)
    f"{XDG_DATA}/vim",
    f"{XDG_DATA}/nvim",
    # My local temporary files directory
    f"{XDG_TEMP}",
    # System files (may require sudo)
    "/etc/ssh/",
)

# ┌───────────┐
# │ Utilities │
# └───────────┘


def run(*args, **kwargs):
    """Run a subcommand, hiding output depending on the log level."""
    pipe = (
        None
        if logging.getLogger(__name__).getEffectiveLevel() <= logging.DEBUG
        else subprocess.DEVNULL
    )
    return (
        subprocess.run(*args, **kwargs, stdin=pipe, stderr=pipe, stdout=pipe).returncode
        == 0
    )


def and_all(it):
    """Conditionally and all the booleans in `it`."""
    return functools.reduce(lambda x, y: x and y, it, True)


def read_bool(query):
    """Interactively ask the user to answer the boolean query `query`."""
    while True:
        choice = input(f"{query} (y/n)? ")
        if choice.lower() in ("no", "n"):
            return False
        if choice.lower() in ("yes", "y"):
            return True
        logging.warning("Must enter yes or no, not %s", repr(choice))


def move_path_dest(args, path):
    """The path to where `move_path` would move `path`."""
    return args.output / "files" / path.relative_to(path.anchor)


def move_path(args, it):
    """Copy each absolute path in it to the backup directory."""
    out = args.output / "files"
    out.mkdir(exist_ok=True)
    for path in it:
        if not path.absolute():
            raise ValueError("Moving paths requires all paths to be absolute", path)
        dest = move_path_dest(args, path)
        # pylint: disable=no-member
        logging.trace(
            "Moved %s -> %s", repr(str(path)), repr(str(dest))
        )  # pylint: disable=E1101
        dest.parent.mkdir(parents=True, exist_ok=True)
        shutil.move(path, dest)


# ┌─────────────────┐
# │ Backup Routines │
# └─────────────────┘


def backup_gpg(args):
    """Backup GPG secret and public keys."""
    if not shutil.which("gpg"):
        logging.warning("GPG executable not found, skipping GPG keyring backup")
        return True
    logging.info("Backing up GPG keyring")
    dest_dir = args.output / "gpg"
    dest_dir.mkdir(exist_ok=True)

    if args.dry_run:
        return True
    return and_all(
        (
            run(["gpg", "--export", "--armor", "--output", str(dest_dir / "keys.gpg")]),
            run(
                [
                    "gpg",
                    "--export-secret-keys",
                    "--armor",
                    "--output",
                    str(dest_dir / "private-keys.gpg"),
                ]
            ),
            run(
                ["gpg", "--export-ownertrust", "--output", str(dest_dir / "armor.gpg")]
            ),
        )
    )


def backup_pass(args):
    """Backup passwords in the pass password manager.

    WARN: This method doesn't save passwords that haven't been comitted.
    """
    if not shutil.which("pass"):
        logging.warning("pass executable not found, skipping pass backup")
        return True
    logging.info("Pushing pass password store to remote")
    if args.dry_run:
        return True
    return run(["pass", "git", "push", "origin", "master"])


def backup_paths(args):
    """Backup paths related to `PATHS`."""
    logging.info("Backing up arbitrary paths")
    it = itertools.chain.from_iterable(
        glob.glob(os.path.expanduser(p), recursive=True) for p in PATHS
    )
    for path in it:
        logging.debug("Found backup path: %s", path)
        if args.dry_run:
            continue
        move_path(args, pathlib.Path(path))


def backup_repos(args):
    """Compress any repositories into archives and then move the compressed
    archives over to the backup directory. The repos are compressed beforehand
    because otherwise we end up moving a lot of tiny files from one directory
    to another and that slows down the backup process immensely.
    """
    logging.info("Backing up repositories")
    res = True
    for repo in subprocess.check_output(["ls-projects"]).split(b"\n"):
        repo = repo.decode("utf-8")
        if not repo:
            continue

        logging.debug("Attempting to backup repository: %s", repo)
        repo = pathlib.Path(repo)
        archive_path = repo.parent / (repo.name + ".tar.gz")

        backup_dest = move_path_dest(args, archive_path)
        if backup_dest.exists():
            logging.warning(
                "Skipping repo backup because destination exists: %s", backup_dest
            )
            continue

        if args.dry_run:
            continue

        if not run(["tar", "czvf", archive_path, "."], cwd=repo):
            logging.error("Failed to compress repo to archive for backup: %s", repo)
            if archive_path.exists():
                archive_path.unlink()
            res = False
        else:
            move_path(args, (archive_path,))
    return res


# The functions used for backing up in the order we want them to backup.
BACKUP_FUNCTIONS = (
    backup_gpg,
    backup_pass,
    backup_paths,
    backup_repos,
)

# ┌────────────────────┐
# │ Script Entry Point │
# └────────────────────┘


def main(args, vargs, parser):
    """Run backup."""
    # pylint: disable=W0613
    logging.info("Creating backup at %s", args.output)

    # If backup directory exists ask user to proceed.
    # Otherwise ask user if they really want to backup or not.
    if args.output.exists():
        proceed = args.no_confirm or read_bool(
            "Backup destination already exists, continue"
        )
        if not proceed:
            logging.info("Skipping backup due to user cancellation")
            return True
    elif not args.no_confirm and not read_bool(
        "Creating a backup will invalidate some files on the system, proceed"
    ):
        logging.info("Skipping backup due to user cancellation")
        return True
    args.output.mkdir(exist_ok=True, parents=True)

    # Run all backup functions in order and return True only when all of
    # them return a non-false value.
    #
    # TODO: Error log when a backupper failed.
    return and_all(func(args) for func in BACKUP_FUNCTIONS)


if __name__ == "__main__":
    import argparse

    from mohkale.pylog.add_level import add_logging_level
    from mohkale.pylog.config import use_config as use_logging_config

    add_logging_level("TRACE", logging.DEBUG - 5)

    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-o",
        "--output",
        metavar="PATH",
        type=pathlib.Path,
        default=pathlib.Path("~/backup").expanduser(),
        help="Dump backup to PATH",
    )
    parser.add_argument(
        "-y",
        "--no-confirm",
        action="store_true",
        help="Assume yes on any interactive queries",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Don't actually perform the backup, just log as if you did",
    )

    logging_group = parser.add_argument_group("Logging")
    logging_group.add_argument(
        "-l",
        "--log-level",
        metavar="LEVEL",
        type=lambda X: getattr(logging, X.upper()),
        help="Level of logging output.",
    )

    args = parser.parse_args()
    vargs = vars(args)

    use_logging_config("backup", level=vargs.pop("log_level"))

    sys.exit(0 if main(args, vargs, parser) else 1)

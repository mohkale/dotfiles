---
# My global config
global:
  # Set the scrape interval to every minute.
  scrape_interval: 60s
  # Evaluate rules every minute.
  evaluation_interval: 60s
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"
    scrape_timeout: 60s

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]
      - targets: ["jellyfin:8096", "gluetun:8096"]
        labels:
          ms_source: jellyfin
      - targets: ["navidrome:4533", "gluetun:4533"]
        labels:
          ms_source: navidrome
      - targets: ["qbit-prometheus:17871"]
        labels:
          ms_source: qbittorrent
      - targets: ["sonarr-prometheus"]
        labels:
          ms_source: sonarr
      - targets: ["radarr-prometheus"]
        labels:
          ms_source: radarr
      - targets: ["prowlarr-prometheus"]
        labels:
          ms_source: prowlarr
      - targets: ["bazarr-prometheus"]
        labels:
          ms_source: bazarr
      - targets: ["lidarr-prometheus"]
        labels:
          ms_source: lidarr
      - targets: ["readarr-prometheus"]
        labels:
          ms_source: readarr
